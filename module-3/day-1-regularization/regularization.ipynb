{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge & Lasso & Regularization\n",
    "\n",
    "## Objectives \n",
    "<a name=\"objectives\"></a>\n",
    "\n",
    "- List methods other than r-squared to assess model fit\n",
    "\n",
    "- Describe regularization's role in regression\n",
    "\n",
    "- Summarize the difference between L1 and L2 norms\n",
    "\n",
    "- Understand the effect of hyper-parameter $\\alpha$ in Ridge and Lasso.\n",
    "\n",
    "- Compare and contrast between Lasso-Ridge-Linear models.\n",
    "\n",
    "- Apply Lasso and Ridge with sklearn and understand the parameters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 0: Review \n",
    "## Review Linear Regression once again:\n",
    "![imune](https://media3.giphy.com/media/l4FGBBs6fjtZXzXCE/giphy.gif?cid=ecf05e47dbb74b8bcd3cf3aafbc86e24452503799b466084&rid=giphy.gif)\n",
    "\n",
    "\n",
    "__Linear Model__\n",
    "\n",
    "\n",
    "$$ Y = w_{0} + w_{1}X_1 + w_{2}X_{2} + \\cdots + w_{p}X_{p} + \\varepsilon $$\n",
    "\n",
    " - We train model to understand the paramaters $w_{i}$ \n",
    " \n",
    " - Use linear algebra or gradient descent to find parameters to minimize:\n",
    " \n",
    " Note that the predictions are given by:\n",
    " \n",
    " $$ \\hat{y}_{i} =  w_{0} + w_{1}X_{i1} + w_{2}X_{i2} + \\cdots + w_{p}X_{i_p}$$\n",
    " \n",
    " Therefore individual errors are given by:\n",
    " \n",
    " $$ e_{i} = y_{i} - \\hat{y}_{i} $$\n",
    " \n",
    " As a result, the residual sum of squares can be expressed as:\n",
    " \n",
    " $$ RSS(\\boldsymbol{w}) = \\sum\\limits_{i=0}^{N} e_{i}^{2}$$\n",
    " \n",
    " \n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\sum\\limits_{i=0}^{N} (y_{i} - w_{0} - w_{1}X_{i1} - w_{2}X_{i2} - \\cdots - w_{p}X_{i_p})^{2} $$\n",
    " \n",
    " And this equation can be written in short hand as:\n",
    " \n",
    " $$ J(\\boldsymbol{w}) = \\rvert \\boldsymbol{y} - X \\boldsymbol{w} \\rvert^{2} $$\n",
    " \n",
    " or with betas as we are used to seeing them:\n",
    " \n",
    " $$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What methods or metrics have you learned to assess model fit?\n",
    "\n",
    "\n",
    "## Another Question: How do those metrics feel about adding more variables to the model?\n",
    "\n",
    "![schitts](https://media1.giphy.com/media/fXtGlVSI2ZB2E1JO0b/giphy.gif?cid=ecf05e47f55093929090866ffd59873c647521e25e164830&rid=giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review\n",
    "<a name=\"review\"></a>\n",
    "\n",
    "\n",
    "\n",
    "[__Overfitting - Underfitting__](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "<img src=\"underfitting_overfitting.png\" alt=\"Bias-Variance\" style=\"width: 500px;\"/>\n",
    "\n",
    "[__Bias - Variance Trade-Off__](http://scott.fortmann-roe.com/docs/BiasVariance.html)\n",
    "\n",
    "<img src=\"bias_variance_trade_off.png\" alt=\"Bias-Variance\" style=\"width: 400px;\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Tools:\n",
    "- AIC & BIC to compare models\n",
    "- Regularization to produce a better model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: AIC & BIC\n",
    "## Calculating AIC and BIC \n",
    "AIC and BIC are information criteria for evaluating model performance. These measures compute the goodness of fit with the estimated parameters, but apply a penalty function on the number of parameters in the model.\n",
    "\n",
    "\n",
    "The BIC is also known as the _Schwarz information criterion (abrv. SIC)_ or the Schwarz-Bayesian information criteria. The AIC is also known as the Akaike information criterion. Both criterion were developed in the 1970s.\n",
    "\n",
    "- AIC is defined as: $2k - 2log(L)$\n",
    "- BIC is defined as: $klog(n) - 2log(L)$  \n",
    "\n",
    "$n$ = sample size <br>\n",
    "$k$ = variables in model <br>\n",
    "$L$ = log of sse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def aic(y, y_pred, k):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    AIC = 2*k - 2*np.log(sse)\n",
    "    \n",
    "    return AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bic(y, y_pred, k, n):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    BIC = np.log(n) + n*np.log(sse/n)\n",
    "    \n",
    "    return BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AIC & BIC in comparsion\n",
    "\n",
    "Both AIC and BIC are only useful in comparing the performance of two different model specifications and **cannot** be used on their own. \n",
    "\n",
    "_**Lower**_ AIC and BIC are better. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Regularization\n",
    "\n",
    "## Regularization Techniques\n",
    "\n",
    "\n",
    "- Why?\n",
    "\n",
    "    - Reduces complexity\n",
    "    \n",
    "    - Reduce the chance of overfitting.\n",
    "    \n",
    "    - Reduces model's variance at the expense of introducing small bias\n",
    "    \n",
    "    - Increases model's interprettability.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Ridge regularization (L2 Norm)\n",
    "![ridge](https://media2.giphy.com/media/3Aie9MmJ0klyM/giphy.gif?cid=ecf05e472724cf8b955fe4da2a1050dd8865bec22b629736&rid=giphy.gif)\n",
    "\n",
    "Instead of minimizing $J(w)$ (least squares method), we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p} w_{i}^{2} $$\n",
    "\n",
    "Function is in sklearn as [Ridge](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "The **goal** of ridge regression is to find  the right alpha that best manages multicolinearity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ridge regression applies a penalizing parameter $\\lambda$ *slope* $^2$, such that a small bias will be introduced to the entire model depending on the value of $\\lambda$, which is called a *hyperparameter*. \n",
    "\n",
    "$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p b_j^2$$\n",
    "\n",
    "The result of applying such a penalizing parameter to the cost function, resulting a different regression model that minimizing the residual sum of square **and** the term $\\lambda \\sum_{j=1}^p b_j^2$. \n",
    "\n",
    "The Ridge regression improves the fit of the original regression line by introducing some bias/changing the slope and intercept of the original line. Recall the way we interpret a regression model Y = mx + b: with every unit increase in x, the outcome y increase by m unit. Therefore, the bigger the coefficient m is, the more the outcome is subjected to changes in predictor x. Ridge regression works by reducing the magnitude of the coefficient m and therefore reducing the effect the predictors have on the outcome. Let's look at a simple example.\n",
    "\n",
    "The ridge regression penalty term contains all of the coefficients squared from the original regression line except for the intercept term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2a: Lasso regularization (L1 Norm)\n",
    "![lasso](https://media3.giphy.com/media/wRKeX8o1eIxxu/giphy.gif?cid=ecf05e47a70490d9dee94f19dd8876390c0ef88243356922&rid=giphy.gif)\n",
    "\n",
    "Instead of minimizing $J(\\boldsymbol{\\omega})$, we will minimize:\n",
    "\n",
    "$$ J_{\\alpha}(\\boldsymbol{w}) = J(\\boldsymbol{w}) + \\alpha\\sum_{i=1}^{p}| w_{i} | $$\n",
    "\n",
    "Function in skelarn as [Lasso](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html)\n",
    "\n",
    "The **goal** of lasso regression is to obtain the subset of predictors and increase model interpretability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression is very similar to Ridge regression except for one difference - the penalty term is not squared but the absolute values of the coefficients muliplied by lambda, expressed by:\n",
    "\n",
    "$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(b_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p \\mid b_j \\mid$$\n",
    "\n",
    "The biggest difference in Ridge and Lasso is that Lasso simultaneously performs variable selection: some coefficients are shrunk to 0, rendering them nonexistence in the original regression model. Therefore, Lasso regression performs very well when you have higher dimensional dataset where some predictors are useless; whereas Ridge works best when all the predictors are needed. \n",
    "\n",
    "<img src=\"https://media.giphy.com/media/AWeYSE0qgpk76/giphy.gif\" width= \"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# implementation \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = sns.load_dataset('mpg')\n",
    "\n",
    "#data = pd.read_csv(\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-2-24-09-ridge-and-lasso-regression/master/auto-mpg.csv\") \n",
    "data = data.sample(50)\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\", \"name\", \"origin\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2745</td>\n",
       "      <td>16.7</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2125</td>\n",
       "      <td>14.5</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2108</td>\n",
       "      <td>15.5</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4294</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.7</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     cylinders  displacement  horsepower  weight  acceleration  model_year\n",
       "271          4         156.0       105.0    2745          16.7          78\n",
       "146          4          90.0        75.0    2125          14.5          74\n",
       "147          4          90.0        75.0    2108          15.5          74\n",
       "74           8         302.0       140.0    4294          16.0          72\n",
       "304          4          91.0        69.0    2130          14.7          79"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = MinMaxScaler()\n",
    "transformed = scale.fit_transform(X)\n",
    "X = pd.DataFrame(transformed, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.223377</td>\n",
       "      <td>0.306358</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.503067</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.132948</td>\n",
       "      <td>0.153385</td>\n",
       "      <td>0.368098</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.132948</td>\n",
       "      <td>0.148292</td>\n",
       "      <td>0.429448</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.602597</td>\n",
       "      <td>0.508671</td>\n",
       "      <td>0.803176</td>\n",
       "      <td>0.460123</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0.054545</td>\n",
       "      <td>0.098266</td>\n",
       "      <td>0.154883</td>\n",
       "      <td>0.380368</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cylinders  displacement  horsepower    weight  acceleration  model_year\n",
       "0        0.2      0.223377    0.306358  0.339125      0.503067    0.666667\n",
       "1        0.2      0.051948    0.132948  0.153385      0.368098    0.333333\n",
       "2        0.2      0.051948    0.132948  0.148292      0.429448    0.333333\n",
       "3        1.0      0.602597    0.508671  0.803176      0.460123    0.166667\n",
       "4        0.2      0.054545    0.098266  0.154883      0.380368    0.750000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth duster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>37.3</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>14.7</td>\n",
       "      <td>79</td>\n",
       "      <td>europe</td>\n",
       "      <td>fiat strada custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>26.8</td>\n",
       "      <td>6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2700</td>\n",
       "      <td>12.9</td>\n",
       "      <td>79</td>\n",
       "      <td>usa</td>\n",
       "      <td>oldsmobile omega brougham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>33.5</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1945</td>\n",
       "      <td>16.8</td>\n",
       "      <td>77</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun f-10 hatchback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2155</td>\n",
       "      <td>16.4</td>\n",
       "      <td>76</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2585</td>\n",
       "      <td>14.5</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>chrysler lebaron medallion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>31.5</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1990</td>\n",
       "      <td>14.9</td>\n",
       "      <td>78</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen scirocco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>31.3</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2542</td>\n",
       "      <td>17.5</td>\n",
       "      <td>80</td>\n",
       "      <td>japan</td>\n",
       "      <td>mazda 626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>2234</td>\n",
       "      <td>12.5</td>\n",
       "      <td>70</td>\n",
       "      <td>europe</td>\n",
       "      <td>bmw 2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>19.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>2310</td>\n",
       "      <td>18.5</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford pinto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2979</td>\n",
       "      <td>19.5</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 504 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>36.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1800</td>\n",
       "      <td>16.4</td>\n",
       "      <td>78</td>\n",
       "      <td>japan</td>\n",
       "      <td>honda civic cvcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>34.1</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81</td>\n",
       "      <td>japan</td>\n",
       "      <td>mazda glc 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>18.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>2933</td>\n",
       "      <td>14.5</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>volvo 145e (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>23.6</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2905</td>\n",
       "      <td>14.3</td>\n",
       "      <td>80</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford mustang cobra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>46.6</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2110</td>\n",
       "      <td>17.9</td>\n",
       "      <td>80</td>\n",
       "      <td>japan</td>\n",
       "      <td>mazda glc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>17.5</td>\n",
       "      <td>8</td>\n",
       "      <td>305.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4215</td>\n",
       "      <td>13.0</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet chevelle malibu classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>26.5</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2565</td>\n",
       "      <td>13.6</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford pinto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>454.0</td>\n",
       "      <td>220.0</td>\n",
       "      <td>4354</td>\n",
       "      <td>9.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet impala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>29.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>2135</td>\n",
       "      <td>16.6</td>\n",
       "      <td>78</td>\n",
       "      <td>japan</td>\n",
       "      <td>honda accord lx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>82</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw pickup</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>4042</td>\n",
       "      <td>14.5</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford gran torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>171.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2984</td>\n",
       "      <td>14.5</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford pinto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>29.8</td>\n",
       "      <td>4</td>\n",
       "      <td>89.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>1845</td>\n",
       "      <td>15.3</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>vokswagen rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>29.5</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1825</td>\n",
       "      <td>12.2</td>\n",
       "      <td>76</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>1940</td>\n",
       "      <td>14.5</td>\n",
       "      <td>77</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen rabbit custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>24.5</td>\n",
       "      <td>4</td>\n",
       "      <td>151.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2740</td>\n",
       "      <td>16.0</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>pontiac sunbird coupe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>20.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>3150</td>\n",
       "      <td>15.7</td>\n",
       "      <td>76</td>\n",
       "      <td>europe</td>\n",
       "      <td>volvo 245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2511</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen 411 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>27.2</td>\n",
       "      <td>4</td>\n",
       "      <td>141.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3190</td>\n",
       "      <td>24.8</td>\n",
       "      <td>79</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>23.5</td>\n",
       "      <td>6</td>\n",
       "      <td>173.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2725</td>\n",
       "      <td>12.6</td>\n",
       "      <td>81</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet citation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>228</th>\n",
       "      <td>18.5</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>3525</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford granada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>43.4</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>2335</td>\n",
       "      <td>23.7</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw dasher (diesel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2395</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford pinto (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>21.5</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>2600</td>\n",
       "      <td>12.8</td>\n",
       "      <td>77</td>\n",
       "      <td>europe</td>\n",
       "      <td>bmw 320i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>32.2</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2265</td>\n",
       "      <td>15.2</td>\n",
       "      <td>80</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2789</td>\n",
       "      <td>15.0</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc gremlin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>36.4</td>\n",
       "      <td>5</td>\n",
       "      <td>121.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2950</td>\n",
       "      <td>19.9</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>audi 5000s (diesel)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>30.9</td>\n",
       "      <td>4</td>\n",
       "      <td>105.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2230</td>\n",
       "      <td>14.5</td>\n",
       "      <td>78</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge omni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3940</td>\n",
       "      <td>13.2</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth volare premier v8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4274</td>\n",
       "      <td>12.0</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet impala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>83.0</td>\n",
       "      <td>61.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>19.0</td>\n",
       "      <td>74</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun 710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3399</td>\n",
       "      <td>11.0</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge dart custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>2288</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun 510 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>82</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevy s-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>27.5</td>\n",
       "      <td>4</td>\n",
       "      <td>134.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2560</td>\n",
       "      <td>14.2</td>\n",
       "      <td>78</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>27.9</td>\n",
       "      <td>4</td>\n",
       "      <td>156.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>2800</td>\n",
       "      <td>14.4</td>\n",
       "      <td>80</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge colt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>hi 1200d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2489</td>\n",
       "      <td>15.0</td>\n",
       "      <td>74</td>\n",
       "      <td>japan</td>\n",
       "      <td>honda civic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>223</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>318.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>4140</td>\n",
       "      <td>13.7</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>dodge monaco brougham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "15   22.0          6         198.0        95.0    2833          15.5   \n",
       "304  37.3          4          91.0        69.0    2130          14.7   \n",
       "307  26.8          6         173.0       115.0    2700          12.9   \n",
       "220  33.5          4          85.0        70.0    1945          16.8   \n",
       "205  28.0          4          97.0        75.0    2155          16.4   \n",
       "388  26.0          4         156.0        92.0    2585          14.5   \n",
       "278  31.5          4          89.0        71.0    1990          14.9   \n",
       "319  31.3          4         120.0        75.0    2542          17.5   \n",
       "23   26.0          4         121.0       113.0    2234          12.5   \n",
       "112  19.0          4         122.0        85.0    2310          18.5   \n",
       "78   21.0          4         120.0        87.0    2979          19.5   \n",
       "248  36.1          4          91.0        60.0    1800          16.4   \n",
       "349  34.1          4          91.0        68.0    1985          16.0   \n",
       "76   18.0          4         121.0       112.0    2933          14.5   \n",
       "336  23.6          4         140.0         NaN    2905          14.3   \n",
       "322  46.6          4          86.0        65.0    2110          17.9   \n",
       "187  17.5          8         305.0       140.0    4215          13.0   \n",
       "206  26.5          4         140.0        72.0    2565          13.6   \n",
       "6    14.0          8         454.0       220.0    4354           9.0   \n",
       "279  29.5          4          98.0        68.0    2135          16.6   \n",
       "394  44.0          4          97.0        52.0    2130          24.6   \n",
       "88   14.0          8         302.0       137.0    4042          14.5   \n",
       "174  18.0          6         171.0        97.0    2984          14.5   \n",
       "332  29.8          4          89.0        62.0    1845          15.3   \n",
       "203  29.5          4          97.0        71.0    1825          12.2   \n",
       "233  29.0          4          97.0        78.0    1940          14.5   \n",
       "234  24.5          4         151.0        88.0    2740          16.0   \n",
       "207  20.0          4         130.0       102.0    3150          15.7   \n",
       "77   22.0          4         121.0        76.0    2511          18.0   \n",
       "299  27.2          4         141.0        71.0    3190          24.8   \n",
       "341  23.5          6         173.0       110.0    2725          12.6   \n",
       "228  18.5          6         250.0        98.0    3525          19.0   \n",
       "326  43.4          4          90.0        48.0    2335          23.7   \n",
       "80   22.0          4         122.0        86.0    2395          16.0   \n",
       "242  21.5          4         121.0       110.0    2600          12.8   \n",
       "321  32.2          4         108.0        75.0    2265          15.2   \n",
       "107  18.0          6         232.0       100.0    2789          15.0   \n",
       "327  36.4          5         121.0        67.0    2950          19.9   \n",
       "269  30.9          4         105.0        75.0    2230          14.5   \n",
       "208  13.0          8         318.0       150.0    3940          13.2   \n",
       "62   13.0          8         350.0       165.0    4274          12.0   \n",
       "145  32.0          4          83.0        61.0    2003          19.0   \n",
       "121  15.0          8         318.0       150.0    3399          11.0   \n",
       "81   28.0          4          97.0        92.0    2288          17.0   \n",
       "397  31.0          4         119.0        82.0    2720          19.4   \n",
       "267  27.5          4         134.0        95.0    2560          14.2   \n",
       "323  27.9          4         156.0       105.0    2800          14.4   \n",
       "28    9.0          8         304.0       193.0    4732          18.5   \n",
       "149  24.0          4         120.0        97.0    2489          15.0   \n",
       "223  15.5          8         318.0       145.0    4140          13.7   \n",
       "\n",
       "     model_year  origin                               name  \n",
       "15           70     usa                    plymouth duster  \n",
       "304          79  europe                 fiat strada custom  \n",
       "307          79     usa          oldsmobile omega brougham  \n",
       "220          77   japan              datsun f-10 hatchback  \n",
       "205          76   japan                     toyota corolla  \n",
       "388          82     usa         chrysler lebaron medallion  \n",
       "278          78  europe                volkswagen scirocco  \n",
       "319          80   japan                          mazda 626  \n",
       "23           70  europe                           bmw 2002  \n",
       "112          73     usa                         ford pinto  \n",
       "78           72  europe                   peugeot 504 (sw)  \n",
       "248          78   japan                   honda civic cvcc  \n",
       "349          81   japan                        mazda glc 4  \n",
       "76           72  europe                    volvo 145e (sw)  \n",
       "336          80     usa                 ford mustang cobra  \n",
       "322          80   japan                          mazda glc  \n",
       "187          76     usa  chevrolet chevelle malibu classic  \n",
       "206          76     usa                         ford pinto  \n",
       "6            70     usa                   chevrolet impala  \n",
       "279          78   japan                    honda accord lx  \n",
       "394          82  europe                          vw pickup  \n",
       "88           73     usa                   ford gran torino  \n",
       "174          75     usa                         ford pinto  \n",
       "332          80  europe                   vokswagen rabbit  \n",
       "203          76  europe                  volkswagen rabbit  \n",
       "233          77  europe           volkswagen rabbit custom  \n",
       "234          77     usa              pontiac sunbird coupe  \n",
       "207          76  europe                          volvo 245  \n",
       "77           72  europe                volkswagen 411 (sw)  \n",
       "299          79  europe                        peugeot 504  \n",
       "341          81     usa                 chevrolet citation  \n",
       "228          77     usa                       ford granada  \n",
       "326          80  europe                 vw dasher (diesel)  \n",
       "80           72     usa                    ford pinto (sw)  \n",
       "242          77  europe                           bmw 320i  \n",
       "321          80   japan                     toyota corolla  \n",
       "107          73     usa                        amc gremlin  \n",
       "327          80  europe                audi 5000s (diesel)  \n",
       "269          78     usa                         dodge omni  \n",
       "208          76     usa         plymouth volare premier v8  \n",
       "62           72     usa                   chevrolet impala  \n",
       "145          74   japan                         datsun 710  \n",
       "121          73     usa                  dodge dart custom  \n",
       "81           72   japan                    datsun 510 (sw)  \n",
       "397          82     usa                         chevy s-10  \n",
       "267          78   japan                      toyota corona  \n",
       "323          80     usa                         dodge colt  \n",
       "28           70     usa                           hi 1200d  \n",
       "149          74   japan                        honda civic  \n",
       "223          77     usa              dodge monaco brougham  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-5789b69a1f68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mridge\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mlasso\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLasso\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    764\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    765\u001b[0m         \"\"\"\n\u001b[1;32m--> 766\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    767\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    545\u001b[0m                          \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_accept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m                          \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m                          multi_output=True, y_numeric=True)\n\u001b[0m\u001b[0;32m    548\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msparse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msolver\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'auto'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sparse_cg'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'sag'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    753\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    754\u001b[0m                     \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 755\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    756\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    576\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    577\u001b[0m             _assert_all_finite(array,\n\u001b[1;32m--> 578\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    579\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Perform t`est train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Build a Ridge, Lasso and regular linear regression model. \n",
    "# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpenalized Linear Regression Coefficients are:[[ -1.54152032  -1.10300143   4.42681896 -20.72186833  -3.48515391\n",
      "   11.5671445 ]]\n",
      "Unpenalized Linear Regression Intercept:[25.98708041]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lin.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lin.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[-6.63794552 -0.         -0.         -6.10331218  0.          6.73802782]\n",
      "Lasso Linear Regression Intercept:[24.95140508]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Ridge' object has no attribute 'coef_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d822d3c5f080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ridge Regression Coefficients are:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Ridge Linear Regression Intercept:{}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mridge\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Ridge' object has no attribute 'coef_'"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression Coefficients are:{}\".format(ridge.coef_))\n",
    "print(\"Ridge Linear Regression Intercept:{}\".format(ridge.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "y_h_ridge_train = ridge.predict(X_train)\n",
    "y_h_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train),(40,1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test),(10,1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train)\n",
    "y_h_lin_test = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(y_h_ridge_train.shape)\n",
    "print(y_h_ridge_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(y_h_lasso_train))\n",
    "print(type(y_h_ridge_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the Residual for Ridge, Lasso, and Unpenalized Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# examine the residual sum of sq\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Part 2c: Crossvalidation to Optimize the Regularization Hyperparameter\n",
    "\n",
    "The regularization strength could sensibly be any nonnegative number, so there's no way to check \"all possible\" values. It's often useful to try several values that are different orders of magnitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train_processed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-4fb53ea5434b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m42\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# upate the names of your datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mtrain_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test_processed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_train_processed' is not defined"
     ]
    }
   ],
   "source": [
    "alphas = [1, 10, 100, 1000, 10000]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    rr = Ridge(alpha=alpha, random_state=42)\n",
    "    # upate the names of your datasets\n",
    "    rr.fit(X_train_processed, y_train)\n",
    "    train_score = rr.score(X_train_processed, y_train)\n",
    "    test_score = cross_val_score(rr, X_test_processed, y_test).mean()\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Ridge $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Practice\n",
    "\n",
    "__Your Turn__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "birds = sns.load_dataset('penguins')\n",
    "\n",
    "# For simplicity's sake we'll limit our analysis to the numeric columns.\n",
    "\n",
    "# numeric = birds[['culmen_length_mm', 'culmen_depth_mm','flipper_length_mm', 'body_mass_g']]\n",
    "\n",
    "\n",
    "# We'll drop the rows with null values\n",
    "\n",
    "cleaned = birds.dropna()\n",
    "X_train, X_test, y_train, y_test = train_test_split(cleaned.drop('body_mass_g',\n",
    "                                                              axis=1),\n",
    "                                                   cleaned['body_mass_g'],\n",
    "                                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>x0_Chinstrap</th>\n",
       "      <th>x0_Gentoo</th>\n",
       "      <th>x1_Dream</th>\n",
       "      <th>x1_Torgersen</th>\n",
       "      <th>x2_MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>55.9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>43.6</td>\n",
       "      <td>13.9</td>\n",
       "      <td>217.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38.8</td>\n",
       "      <td>20.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>47.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>212.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>53.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>205.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     culmen_length_mm  culmen_depth_mm  flipper_length_mm  x0_Chinstrap  \\\n",
       "321              55.9             17.0              228.0           0.0   \n",
       "265              43.6             13.9              217.0           0.0   \n",
       "36               38.8             20.0              190.0           0.0   \n",
       "308              47.5             14.0              212.0           0.0   \n",
       "191              53.5             19.9              205.0           1.0   \n",
       "\n",
       "     x0_Gentoo  x1_Dream  x1_Torgersen  x2_MALE  \n",
       "321        1.0       0.0           0.0      1.0  \n",
       "265        1.0       0.0           0.0      0.0  \n",
       "36         0.0       1.0           0.0      1.0  \n",
       "308        1.0       0.0           0.0      0.0  \n",
       "191        0.0       1.0           0.0      1.0  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe = OneHotEncoder(drop='first')\n",
    "dummies = ohe.fit_transform(X_train[['species', 'island', 'sex']])\n",
    "dummies_df = pd.DataFrame(dummies.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_train.index)\n",
    "X_train_df = pd.concat([X_train[['culmen_length_mm', 'culmen_depth_mm',\n",
    "                                'flipper_length_mm']], dummies_df], axis=1)\n",
    "X_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>culmen_length_mm</th>\n",
       "      <th>culmen_depth_mm</th>\n",
       "      <th>flipper_length_mm</th>\n",
       "      <th>x0_Chinstrap</th>\n",
       "      <th>x0_Gentoo</th>\n",
       "      <th>x1_Dream</th>\n",
       "      <th>x1_Torgersen</th>\n",
       "      <th>x2_MALE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>39.5</td>\n",
       "      <td>16.7</td>\n",
       "      <td>178.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>46.9</td>\n",
       "      <td>14.6</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>42.1</td>\n",
       "      <td>19.1</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>49.8</td>\n",
       "      <td>17.3</td>\n",
       "      <td>198.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>41.1</td>\n",
       "      <td>18.2</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     culmen_length_mm  culmen_depth_mm  flipper_length_mm  x0_Chinstrap  \\\n",
       "30               39.5             16.7              178.0           0.0   \n",
       "317              46.9             14.6              222.0           0.0   \n",
       "79               42.1             19.1              195.0           0.0   \n",
       "201              49.8             17.3              198.0           1.0   \n",
       "63               41.1             18.2              192.0           0.0   \n",
       "\n",
       "     x0_Gentoo  x1_Dream  x1_Torgersen  x2_MALE  \n",
       "30         0.0       1.0           0.0      0.0  \n",
       "317        1.0       0.0           0.0      0.0  \n",
       "79         0.0       0.0           1.0      1.0  \n",
       "201        0.0       1.0           0.0      0.0  \n",
       "63         0.0       0.0           0.0      1.0  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies2 = ohe.fit_transform(X_test[['species', 'island', 'sex']])\n",
    "dummies2_df = pd.DataFrame(dummies2.todense(), columns=ohe.get_feature_names(),\n",
    "                         index=X_test.index)\n",
    "X_test_df = pd.concat([X_test[['culmen_length_mm', 'culmen_depth_mm',\n",
    "                                'flipper_length_mm']], dummies2_df], axis=1)\n",
    "X_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10000, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = Lasso(alpha=10000)\n",
    "lasso.fit(X_train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[ 0. -0.  0. -0.  0. -0. -0.  0.]\n",
      "Lasso Linear Regression Intercept:4214.357429718875\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_h_lasso_train = lasso.predict(X_train_df)\n",
    "y_h_lasso_test = lasso.predict(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Lasso Model 164365547.188755\n",
      "Test Error Lasso Model 50911866.10901437\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "alphas = [0.1, 1, 10, 50, 100]\n",
    "train_scores = []\n",
    "test_scores = []\n",
    "\n",
    "for alpha in alphas:\n",
    "    lr = Lasso(alpha=alpha, random_state=42)\n",
    "    # upate the names of your datasets\n",
    "    lr.fit(X_train_df, y_train)\n",
    "    train_score = lr.score(X_train_df, y_train)\n",
    "    test_score = cross_val_score(lr, X_test_df, y_test).mean()\n",
    "    \n",
    "    train_scores.append(train_score)\n",
    "    test_scores.append(test_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use('fivethirtyeight')\n",
    "fig, ax = plt.subplots()\n",
    "plt.xscale('log')\n",
    "plt.title('Lasso $R^2$ as a function of regularization strength')\n",
    "ax.set_xlabel('Regularization strength $\\lambda$')\n",
    "ax.set_ylabel('$R^2$')\n",
    "ax.plot(alphas, train_scores, label='train')\n",
    "ax.plot(alphas, test_scores, label='test')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Try at least 3 different model specifications, using polynomials, interaction terms, etc\n",
    "- Group 1: Use AIC and BIC to pick your \"best\" model specification using Linear Regression\n",
    "- Group 2: Use Ridge AND experiement with different values of alpha to find the \"best\" model. Compare MSE in train and test for each model specification.\n",
    "- Group 3: Use Lasso AND experiment with different values of alpha to find the \"best\" model. Compare MSE in train and test for each model specification.\n",
    "- Report your observations.\n",
    "- A graph comparing your findings and suggesting a model specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4: Summary\n",
    "\n",
    "#### Effect of $\\alpha$ in Lasso and Ridge\n",
    "\n",
    "<img src=\"lasso_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<img src=\"ridge_effect_of_lambda.png\" alt=\"Lasso-Lambda\" style=\"width: 500px;\"/>\n",
    "\n",
    "<a name='questions'></a>\n",
    "### Questions\n",
    "\n",
    "\n",
    "\n",
    "Q. Should I do normalization for Lasso or Ridge?\n",
    "\n",
    "A. Yes? Why?\n",
    "\n",
    "Q. When we know that Ridge and Lasso is better than vanilla linear regression?\n",
    "\n",
    "A. High variation in your model --> Colinearity and too many variables.\n",
    "\n",
    "Q. How do we know whether we should choose Lasso or Ridge?\n",
    "\n",
    "A. Most of the time they perform very similar but Lasso has the feature selection property, ridge doesn't have this.\n",
    "\n",
    "Q: How do we choose $\\lambda$?\n",
    "\n",
    "A. [sklearn gridsearch](https://scikit-learn.org/stable/modules/grid_search.html#grid-search) for small models or random grid search for bigger models.\n",
    "\n",
    "#### Appendix\n",
    "<a name='appendix'></a>\n",
    "\n",
    "Here I would like to add some reading material that I found useful while working with the code.\n",
    "\n",
    "\n",
    "-  [On ridge and lasso](https://bradleyboehmke.github.io/HOML/regularized-regression.html)\n",
    "\n",
    "- [pd.get_dummies or OneHotEncoder? - Read second answer](https://stackoverflow.com/questions/36631163/pandas-get-dummies-vs-sklearns-onehotencoder-what-are-the-pros-and-cons)\n",
    "\n",
    "- [On dummy variable trap](https://www.algosome.com/articles/dummy-variable-trap-regression.html)\n",
    "\n",
    "- [sklearn.preprocessing.PolynomialFeatures documentation](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)\n",
    "\n",
    "- [A great notebook on Lasso and Ridge](https://github.com/gokererdogan/JaverianaMLCourse/blob/master/Lectures/05.pdf)\n",
    "\n",
    "- [Another good blog post on Lasso and Ridge](https://www.analyticsvidhya.com/blog/2016/01/complete-tutorial-ridge-lasso-regression-python/)\n",
    "\n",
    "- Learn.co -- Section-28 Lasso-Ridge\n",
    "\n",
    "- [Toward Datascience Article](https://towardsdatascience.com/understanding-the-bias-variance-tradeoff-165e6942b229)\n",
    "\n",
    "- [ISLR](http://faculty.marshall.usc.edu/gareth-james/ISL/) 2.2.2 The Bias-Variance Trade-off and 6.2 Shrinkage Methods\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Image Sources in order of appearance: \n",
    "- https://docs.aws.amazon.com/machine-learning/latest/dg/model-fit-underfitting-vs-overfitting.html\n",
    "\n",
    "- https://towardsdatascience.com/ensemble-methods-bagging-boosting-and-stacking-c9214a10a205\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
